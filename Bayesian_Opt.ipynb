{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition.analytic import LogExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "import gpytorch\n",
    "from botorch.models.transforms import Normalize\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "area1 = 0.001485182056299268\n",
    "area2 = 0.0019705673066026984\n",
    "area3 = 0.004624429474288485\n",
    "area4 = 0.0018803643706964024\n",
    "area5 = 0.00043436256803102525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = torch.tensor([[0.81411, 0.00011, 0.0004598], [0.88812, 0.00012, 0.0005016], [0.96213, 0.00013, 0.0005434], [0.66609, 0.00009, 0.0003762], [0.59208, 0.00008, 0.0003344]])\n",
    "train_Y = torch.tensor([[area1], [area2], [area3], [area4], [area5]])  \n",
    "\n",
    "bounds = torch.tensor([\n",
    "    [0.1, 0.00005, 0.00020], \n",
    "    [1, 0.00014, 0.00065]   \n",
    "], dtype=torch.float64\n",
    ")\n",
    "\n",
    "\n",
    "outcome_transform = Standardize(m=1)\n",
    "\n",
    "# Optimization loop\n",
    "num_iterations = 25  \n",
    "tolerance = 1e-6  \n",
    "previous_best_area = float('inf')\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Fit the GP model\n",
    "    model = SingleTaskGP(train_X, train_Y, input_transform=Normalize(d=3), outcome_transform=outcome_transform)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "   \n",
    "    acq_func = LogExpectedImprovement(model, best_f=train_Y.min(), maximize=False)\n",
    "\n",
    "    \n",
    "    candidate, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=bounds,\n",
    "        q=1,  \n",
    "        num_restarts=10, \n",
    "        raw_samples=50,  \n",
    "    )\n",
    "\n",
    "    # Print the suggested new parameters\n",
    "    print(f\"Iteration {i+1}: Suggested new parameters (n, tau_star, B):\", candidate)\n",
    "\n",
    "    # Manually input the new area value for the suggested parameters\n",
    "    new_area = float(input(\"Enter the new area value for the suggested parameters: \"))\n",
    "\n",
    "    train_X = torch.cat([train_X, candidate], dim=0)\n",
    "    train_Y = torch.cat([train_Y, torch.tensor([[new_area]])], dim=0)\n",
    "\n",
    "  \n",
    "    current_best_area = train_Y.min().item()\n",
    "    print(f\"Iteration {i+1}: Best area so far: {current_best_area}\")\n",
    "\n",
    "    if abs(previous_best_area - current_best_area) < tolerance:\n",
    "        print(f\"Converged after {i+1} iterations with minimal error.\")\n",
    "        break\n",
    "\n",
    "    previous_best_area = current_best_area\n",
    "\n",
    "# Final output of the best found parameters and corresponding area\n",
    "best_params = train_X[train_Y.argmin()]\n",
    "best_area = train_Y.min().item()\n",
    "print(f\"Best parameters (n, tau_star, B): {best_params}, with area: {best_area}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
