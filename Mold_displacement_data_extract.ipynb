{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code extracts the displacement and time values from xml data I got from the moldflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('D:\\\\SMC Optimization\\\\SMC_Mock_Sim\\\\press_disp.xml') #Directory of the XML file\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for time_block, dept_block in zip(root.findall('.//Block//IndpVar'), root.findall('.//Block')):\n",
    "    # Get the time value\n",
    "    time_value = time_block.attrib.get('Value')\n",
    "    \n",
    "    # Get the ddisplamcement value\n",
    "    dept_value = dept_block.find('DeptValues').text.strip()\n",
    "    \n",
    "    # Append both values as a tuple (time_value, dept_value) to data\n",
    "    data.append((time_value, dept_value))\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.array([(float(x), float(y)) for x, y in data])\n",
    "\n",
    "# Separate the array into x and y components\n",
    "x_values = data_array[:, 0]  # First column for x-axis values\n",
    "y_values = data_array[:, 1]  # Second column for y-axis values\n",
    "\n",
    "# Plot the curve\n",
    "plt.plot(x_values, y_values, marker='o', linestyle='-', color='b', label='Data Curve')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Press Dispalcement m')\n",
    "plt.title('Curve Plot for the Given Data')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('D:\\\\SMC Optimization\\\\SMC_Mock_Sim\\\\Mock_Simulation\\\\press_displacement_real.xml') #Directory of the XML file\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = []\n",
    "\n",
    "for time_block, dept_block in zip(root.findall('.//Block//IndpVar'), root.findall('.//Block')):\n",
    "    # Get the time value\n",
    "    time_value = time_block.attrib.get('Value')\n",
    "    \n",
    "    # Get the ddisplamcement value\n",
    "    dept_value = dept_block.find('DeptValues').text.strip()\n",
    "    \n",
    "    # Append both values as a tuple (time_value, dept_value) to data\n",
    "    real_data.append((time_value, dept_value))\n",
    "\n",
    "print(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_array = np.array([(float(x), float(y)) for x, y in real_data])\n",
    "\n",
    "# Separate the array into x and y components\n",
    "real_time = real_data_array[:, 0]  # First column for x-axis values\n",
    "real_disp = real_data_array[:, 1]  # Second column for y-axis values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_1 = ET.parse('D:\\\\SMC Optimization\\\\SMC_Mock_Sim\\\\Mock_Simulation\\\\press_displacement_g1.xml') #Directory of the XML file\n",
    "root_1 = tree_1.getroot()\n",
    "\n",
    "guess1_data = []\n",
    "\n",
    "for time_block, dept_block in zip(root_1.findall('.//Block//IndpVar'), root_1.findall('.//Block')):\n",
    "    # Get the time value\n",
    "    time_value = time_block.attrib.get('Value')\n",
    "    \n",
    "    # Get the ddisplamcement value\n",
    "    dept_value = dept_block.find('DeptValues').text.strip()\n",
    "    \n",
    "    # Append both values as a tuple (time_value, dept_value) to data\n",
    "    guess1_data.append((time_value, dept_value))\n",
    "\n",
    "print(guess1_data)\n",
    "\n",
    "guess1_data_array = np.array([(float(x), float(y)) for x, y in guess1_data])\n",
    "\n",
    "# Separate the array into x and y components\n",
    "guess1_time = guess1_data_array[:, 0]  # First column for x-axis values\n",
    "guess1_disp = guess1_data_array[:, 1]  # Second column for y-axis values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_2 = ET.parse('D:\\\\SMC Optimization\\\\SMC_Mock_Sim\\\\Mock_Simulation\\\\press_displacement_g2.xml') #Directory of the XML file\n",
    "root_2 = tree_2.getroot()\n",
    "\n",
    "guess2_data = []\n",
    "\n",
    "for time_block, dept_block in zip(root_2.findall('.//Block//IndpVar'), root_2.findall('.//Block')):\n",
    "    # Get the time value\n",
    "    time_value = time_block.attrib.get('Value')\n",
    "    \n",
    "    # Get the ddisplamcement value\n",
    "    dept_value = dept_block.find('DeptValues').text.strip()\n",
    "    \n",
    "    # Append both values as a tuple (time_value, dept_value) to data\n",
    "    guess2_data.append((time_value, dept_value))\n",
    "\n",
    "print(guess2_data)\n",
    "\n",
    "guess2_data_array = np.array([(float(x), float(y)) for x, y in guess2_data])\n",
    "\n",
    "# Separate the array into x and y components\n",
    "guess2_time = guess2_data_array[:, 0]  # First column for x-axis values\n",
    "guess2_disp = guess2_data_array[:, 1]  # Second column for y-axis values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_3 = ET.parse('D:\\\\SMC Optimization\\\\SMC_Mock_Sim\\\\Mock_Simulation\\\\press_displacement_g3.xml') #Directory of the XML file\n",
    "root_3 = tree_3.getroot()\n",
    "\n",
    "guess3_data = []\n",
    "\n",
    "for time_block, dept_block in zip(root_3.findall('.//Block//IndpVar'), root_3.findall('.//Block')):\n",
    "    # Get the time value\n",
    "    time_value = time_block.attrib.get('Value')\n",
    "    \n",
    "    # Get the ddisplamcement value\n",
    "    dept_value = dept_block.find('DeptValues').text.strip()\n",
    "    \n",
    "    # Append both values as a tuple (time_value, dept_value) to data\n",
    "    guess3_data.append((time_value, dept_value))\n",
    "\n",
    "print(guess3_data)\n",
    "\n",
    "guess3_data_array = np.array([(float(x), float(y)) for x, y in guess3_data])\n",
    "\n",
    "# Separate the array into x and y components\n",
    "guess3_time = guess3_data_array[:, 0]  # First column for x-axis values\n",
    "guess3_disp = guess3_data_array[:, 1]  # Second column for y-axis values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_4 = ET.parse('D:\\\\SMC Optimization\\\\SMC_Mock_Sim\\\\Mock_Simulation\\\\press_displacement_g4.xml') #Directory of the XML file\n",
    "root_4 = tree_4.getroot()\n",
    "\n",
    "guess4_data = []\n",
    "\n",
    "for time_block, dept_block in zip(root_4.findall('.//Block//IndpVar'), root_4.findall('.//Block')):\n",
    "    # Get the time value\n",
    "    time_value = time_block.attrib.get('Value')\n",
    "    \n",
    "    # Get the ddisplamcement value\n",
    "    dept_value = dept_block.find('DeptValues').text.strip()\n",
    "    \n",
    "    # Append both values as a tuple (time_value, dept_value) to data\n",
    "    guess4_data.append((time_value, dept_value))\n",
    "\n",
    "print(guess4_data)\n",
    "\n",
    "guess4_data_array = np.array([(float(x), float(y)) for x, y in guess4_data])\n",
    "\n",
    "# Separate the array into x and y components\n",
    "guess4_time = guess4_data_array[:, 0]  # First column for x-axis values\n",
    "guess4_disp = guess4_data_array[:, 1]  # Second column for y-axis values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_5 = ET.parse('D:\\\\SMC Optimization\\\\SMC_Mock_Sim\\\\Mock_Simulation\\\\press_displacement_g5.xml') #Directory of the XML file\n",
    "root_5 = tree_5.getroot()\n",
    "\n",
    "guess5_data = []\n",
    "\n",
    "for time_block, dept_block in zip(root_5.findall('.//Block//IndpVar'), root_5.findall('.//Block')):\n",
    "    # Get the time value\n",
    "    time_value = time_block.attrib.get('Value')\n",
    "    \n",
    "    # Get the ddisplamcement value\n",
    "    dept_value = dept_block.find('DeptValues').text.strip()\n",
    "    \n",
    "    # Append both values as a tuple (time_value, dept_value) to data\n",
    "    guess5_data.append((time_value, dept_value))\n",
    "\n",
    "print(guess5_data)\n",
    "\n",
    "guess5_data_array = np.array([(float(x), float(y)) for x, y in guess5_data])\n",
    "\n",
    "# Separate the array into x and y components\n",
    "guess5_time = guess5_data_array[:, 0]  # First column for x-axis values\n",
    "guess5_disp = guess5_data_array[:, 1]  # Second column for y-axis values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_sim = interp1d(guess1_time, guess1_disp, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "# Interpolate y_sim at the x positions of x_exp\n",
    "y_sim_interp = interpolate_sim(real_time)\n",
    "\n",
    "# Now calculate the error metrics\n",
    "mse = mean_squared_error(real_disp, y_sim_interp)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(real_disp, y_sim_interp)\n",
    "\n",
    "# Print the error metrics\n",
    "print(\"Interpolated MSE:\", mse)\n",
    "print(\"Interpolated RMSE:\", rmse)\n",
    "print(\"Interpolated MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_sim_2 = interp1d(guess2_time, guess2_disp, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "# Interpolate \n",
    "y_sim_interp_2 = interpolate_sim_2(real_time)\n",
    "\n",
    "# calculate the error metrics\n",
    "mse_2 = mean_squared_error(real_disp, y_sim_interp_2)\n",
    "rmse_2 = np.sqrt(mse_2)\n",
    "mae_2 = mean_absolute_error(real_disp, y_sim_interp_2)\n",
    "\n",
    "# Print the error metrics\n",
    "print(\"Interpolated MSE:\", mse_2)\n",
    "print(\"Interpolated RMSE:\", rmse_2)\n",
    "print(\"Interpolated MAE:\", mae_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interpolate_sim_3 = interp1d(guess3_time, guess3_disp, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "# Interpolate \n",
    "y_sim_interp_3 = interpolate_sim_3(real_time)\n",
    "\n",
    "# calculate the error metrics\n",
    "mse_3 = mean_squared_error(real_disp, y_sim_interp_3)\n",
    "rmse_3 = np.sqrt(mse_2)\n",
    "mae_3 = mean_absolute_error(real_disp, y_sim_interp_3)\n",
    "\n",
    "# Print the error metrics\n",
    "print(\"Interpolated MSE:\", mse_3)\n",
    "print(\"Interpolated RMSE:\", rmse_3)\n",
    "print(\"Interpolated MAE:\", mae_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interpolate_sim_4 = interp1d(guess4_time, guess4_disp, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "# Interpolate \n",
    "y_sim_interp_4 = interpolate_sim_4(real_time)\n",
    "\n",
    "# calculate the error metrics\n",
    "mse_4 = mean_squared_error(real_disp, y_sim_interp_4)\n",
    "rmse_4 = np.sqrt(mse_4)\n",
    "mae_4 = mean_absolute_error(real_disp, y_sim_interp_4)\n",
    "\n",
    "# Print the error metrics\n",
    "print(\"Interpolated MSE:\", mse_4)\n",
    "print(\"Interpolated RMSE:\", rmse_4)\n",
    "print(\"Interpolated MAE:\", mae_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_sim_5 = interp1d(guess5_time, guess5_disp, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "# Interpolate \n",
    "y_sim_interp_5 = interpolate_sim_5(real_time)\n",
    "\n",
    "# calculate the error metrics\n",
    "mse_5 = mean_squared_error(real_disp, y_sim_interp_5)\n",
    "rmse_5 = np.sqrt(mse_5)\n",
    "mae_5 = mean_absolute_error(real_disp, y_sim_interp_5)\n",
    "\n",
    "# Print the error metrics\n",
    "print(\"Interpolated MSE:\", mse_5)\n",
    "print(\"Interpolated RMSE:\", rmse_5)\n",
    "print(\"Interpolated MAE:\", mae_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 5 guessed n,B and tau_star values we got error values. Using this values train the GP and get a new candidate for the next simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition.analytic import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "import gpytorch\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor([[0.75, 0.00011, 0.00042], [0.73, 0.00009, 0.00041],[0.745, 0.000095, 0.000425],[0.735, 0.000105, 0.000415], [0.74, 0.000102, 0.000420]])\n",
    "train_Y = torch.tensor([[1.3007484506985306e-06], [4.598039412852103e-06], [3.1942273973753585e-07],[3.3996733650018695e-06],[1.2456903626389277e-06]])\n",
    "\n",
    "\n",
    "print(\"train_X dimensions:\", train_X.shape)\n",
    "print(\"train_Y dimensions:\", train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_transform = Standardize(m=1)\n",
    "#likelihood = GaussianLikelihood()\n",
    "model = SingleTaskGP(train_X, train_Y,outcome_transform=outcome_transform,)\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = torch.stack([torch.tensor([0.72, 0.00008, 0.00040]), torch.tensor([0.75, 0.00012, 0.00043])])\n",
    "\n",
    "for _ in range(25):  # Number of iterations\n",
    "    acq_func = ExpectedImprovement(model, best_f=train_Y.min(), maximize=False)\n",
    "    candidate, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=bounds,\n",
    "        q=1,  # Number of new candidates to find\n",
    "        num_restarts=5,  # Optimization restarts\n",
    "        raw_samples=20,  # Samples drawn to initialize optimization\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Suggested new parameters (n, tau_star, B):\", candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
