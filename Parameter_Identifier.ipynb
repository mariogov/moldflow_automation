{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.acquisition.analytic import LogExpectedImprovement\n",
    "from botorch.acquisition import qLogExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "import gpytorch\n",
    "import win32com.client\n",
    "from botorch.models.transforms import Normalize\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import qmc\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from utils import parse_real_disp, CABC_Displacement, CABC_Force, parse_real_force\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Parameter Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds\n",
    "n_bounds = (0.0, 1.0)\n",
    "tau_star_bounds = (400000,0, 7000000.0)\n",
    "# B_bounds_log = (np.log10(1.0e+14), np.log10(1.916e+19))  # log10 scaling\n",
    "tau_w_bounds = (0.001, 1.0)\n",
    "m_bounds = (0.1, 1.9)\n",
    "\n",
    "# LHs Sampling\n",
    "sampler = qmc.LatinHypercube(d=4)\n",
    "sample = sampler.random(10)  # 5 samples\n",
    "\n",
    "# # Scaling\n",
    "n_values = sample[:, 0] * (n_bounds[1] - n_bounds[0]) + n_bounds[0]\n",
    "tau_star_values = sample[:, 1] * (tau_star_bounds[1] - tau_star_bounds[0]) + tau_star_bounds[0]\n",
    "# B_values = 10 ** (sample[:, 2] * (B_bounds_log[1] - B_bounds_log[0]) + B_bounds_log[0])\n",
    "tau_w_values = sample[:, 2] * (tau_w_bounds[1] - tau_w_bounds[0]) + tau_w_bounds[0]\n",
    "m_values = sample[:, 3] * (m_bounds[1] - m_bounds[0]) + m_bounds[0]\n",
    "\n",
    "# # save2CSV\n",
    "df = pd.DataFrame({\n",
    "    'n': n_values,\n",
    "    'tau_star': tau_star_values,\n",
    "    # 'B': B_values,\n",
    "    'tau_w': tau_w_values,\n",
    "    'm': m_values\n",
    "})\n",
    "df.to_csv(\"combined_LHS_parameters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML Parsing - Master Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "real_disp_path = \"H:\\\\Real_data\\\\press_displacement_real.xml\"\n",
    "real_force_path = \"H:\\\\Real_data\\\\press_force_real.xml\"\n",
    "\n",
    "# Displacement XML\n",
    "\n",
    "# real_disp_time, real_disp = parse_real_disp(real_disp_path)\n",
    "\n",
    "# real_tree = ET.parse(real_disp_path)\n",
    "# real_root = real_tree.getroot()\n",
    "# real_data = []\n",
    "# guess_data_all = {}\n",
    "\n",
    "# for time_block, dept_block in zip(real_root.findall('.//Block//IndpVar'), real_root.findall('.//Block')):\n",
    "\n",
    "#     time_value = time_block.attrib.get('Value')\n",
    "#     dept_value = dept_block.find('DeptValues').text.strip()\n",
    "#     real_data.append((time_value, dept_value))\n",
    "\n",
    "# real_data_array = np.array([(float(x), float(y)) for x, y in real_data])\n",
    "# real_time = real_data_array[:, 0]  \n",
    "# real_disp = real_data_array[:, 1] * 0.0001019716\n",
    "\n",
    "\n",
    "# Force XML\n",
    "\n",
    "real_force_time, real_force = parse_real_force(real_force_path)\n",
    "\n",
    "def calculate_area_between_curves(real_time, real_disp, guess_time, guess_disp):\n",
    "    common_time = np.linspace(0.0, max(real_time.max(), guess_time.max()), num=200)\n",
    "\n",
    "    # Resample both curves on this time grid\n",
    "    real_disp_resampled = np.interp(common_time, real_time, real_disp)\n",
    "    guess_disp_resampled = np.interp(common_time, guess_time, guess_disp)\n",
    "\n",
    "    mse = np.mean((real_disp_resampled-guess_disp_resampled)**2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "real_data_directory = \"H:\\\\Real_data\\\\press_force_real.xml\"\n",
    "areas = []\n",
    "area_data = []\n",
    "\n",
    "real_tree = ET.parse(real_data_directory)\n",
    "real_root = real_tree.getroot()\n",
    "real_data = []\n",
    "guess_data_all = {}\n",
    "\n",
    "count = 0\n",
    "\n",
    "for time_block, dept_block in zip(real_root.findall('.//Block//IndpVar'), real_root.findall('.//Block')):\n",
    "    if count >=  27:\n",
    "        break  # Stop the loop after collecting 27 values\n",
    "\n",
    "    time_value = time_block.attrib.get('Value')\n",
    "    dept_value = dept_block.find('DeptValues').text.strip()\n",
    "    real_data.append((time_value, dept_value))\n",
    "\n",
    "    count += 1\n",
    "\n",
    "real_data_array = np.array([(float(x), float(y)) for x, y in real_data])\n",
    "real_time = real_data_array[:, 0]  \n",
    "real_disp = real_data_array[:, 1]   / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_info = [\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\60percent4STACKBAR150bar03mms388g.txt\",  #0\n",
    "#         \"force_start\"   : \"31.07.2025 10:39:06.150461\",\n",
    "#         \"force_end\"     : \"31.07.2025 10:39:24.070461\",\n",
    "#         \"pos_start\"     : \"31.07.2025 10:39:24.070461\",\n",
    "#         \"pos_end\"       : \"31.07.2025 10:42:34.610461\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\60percent4STACKBAR150bar07mms384g.txt\",  #1\n",
    "#         \"force_start\"   : \"31.07.2025 10:18:27.193997\",\n",
    "#         \"force_end\"     : \"31.07.2025 10:18:35.113997\",\n",
    "#         \"pos_start\"     : \"31.07.2025 10:18:35.113997\",\n",
    "#         \"pos_end\"       : \"31.07.2025 10:20:44.573997\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\60percent4STACKBAR150bar11mms414g.txt\",  #2\n",
    "#         \"force_start\"   : \"30.07.2025 13:43:44.197899\",\n",
    "#         \"force_end\"     : \"30.07.2025 13:43:49.057899\",\n",
    "#         \"pos_start\"     : \"30.07.2025 13:43:49.057899\",\n",
    "#         \"pos_end\"       : \"30.07.2025 13:46:49.957899\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\60percent4STACKCENTER150bar03mms396g.txt\", #3\n",
    "#         \"force_start\"   : \"29.07.2025 15:27:01.321079\",\n",
    "#         \"force_end\"     : \"29.07.2025 15:27:19.181079\",\n",
    "#         \"pos_start\"     : \"29.07.2025 15:27:19.181079\",\n",
    "#         \"pos_end\"       : \"29.07.2025 15:30:46.881079\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\60percent4STACKCENTER150bar07mms398g.txt\", #4\n",
    "#         \"force_start\"   : \"30.07.2025 12:19:49.167098\",\n",
    "#         \"force_end\"     : \"30.07.2025 12:19:57.487098\",\n",
    "#         \"pos_start\"     : \"30.07.2025 12:19:57.487098\",\n",
    "#         \"pos_end\"       : \"30.07.2025 12:21:55.287098\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\60percent4STACKCENTER150bar11mms393g.txt\", #5\n",
    "#         \"force_start\"   : \"30.07.2025 12:46:38.439119\",\n",
    "#         \"force_end\"     : \"30.07.2025 12:46:43.619119\",\n",
    "#         \"pos_start\"     : \"30.07.2025 12:46:43.619119\",\n",
    "#         \"pos_end\"       : \"30.07.2025 12:50:18.619119\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\60percent4STACKCENTER200bar11mms365g.txt\",#6\n",
    "#         \"force_start\"   : \"31.07.2025 11:00:47.633201\",\n",
    "#         \"force_end\"     : \"31.07.2025 11:00:53.213201\",\n",
    "#         \"pos_start\"     : \"31.07.2025 11:00:53.213201\",\n",
    "#         \"pos_end\"       : \"31.07.2025 11:06:35.493201\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\80percent4STACKBAR150bar03mms508g.txt\", #7\n",
    "#         \"force_start\"   : \"30.07.2025 11:47:26.451826\",\n",
    "#         \"force_end\"     : \"30.07.2025 11:47:42.371826\",\n",
    "#         \"pos_start\"     : \"30.07.2025 11:47:42.371826\",\n",
    "#         \"pos_end\"       : \"30.07.2025 11:50:53.831826\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\80percent4STACKBAR150bar07mms525g.txt\", #8\n",
    "#         \"force_start\"   : \"31.07.2025 14:21:37.055615\",\n",
    "#         \"force_end\"     : \"31.07.2025 14:21:43.535615\",\n",
    "#         \"pos_start\"     : \"31.07.2025 14:21:43.535615\",\n",
    "#         \"pos_end\"       : \"31.07.2025 14:24:04.975615\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\80percent4STACKBAR150bar11mms531g.txt\", #9\n",
    "#         \"force_start\"   : \"31.07.2025 14:49:31.716399\",\n",
    "#         \"force_end\"     : \"31.07.2025 14:49:35.816399\",\n",
    "#         \"pos_start\"     : \"31.07.2025 14:49:35.816399\",\n",
    "#         \"pos_end\"       : \"31.07.2025 15:01:25.776399\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\80percent4STACKCENTER150bar03mms542g.txt\", #10\n",
    "#         \"force_start\"   : \"31.07.2025 09:07:08.361246\",\n",
    "#         \"force_end\"     : \"31.07.2025 09:07:23.161246\",\n",
    "#         \"pos_start\"     : \"31.07.2025 09:07:23.161246\",\n",
    "#         \"pos_end\"       : \"31.07.2025 09:09:48.641246\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\80percent4STACKCENTER150bar07mms527g.txt\", #11\n",
    "#         \"force_start\"   : \"30.07.2025 15:33:47.945013\",\n",
    "#         \"force_end\"     : \"30.07.2025 15:33:54.465013\",\n",
    "#         \"pos_start\"     : \"30.07.2025 15:33:54.465013\",\n",
    "#         \"pos_end\"       : \"30.07.2025 15:36:35.305013\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\80percent4STACKCENTER150bar11mms543g.txt\", #12\n",
    "#         \"force_start\"   : \"31.07.2025 09:56:19.454633\",\n",
    "#         \"force_end\"     : \"31.07.2025 09:56:23.494633\",\n",
    "#         \"pos_start\"     : \"31.07.2025 09:56:23.494633\",\n",
    "#         \"pos_end\"       : \"31.07.2025 09:58:13.974633\"  \n",
    "#     },\n",
    "#     {\n",
    "#         \"path\" : \"H:\\\\DLR Press Data\\\\SPLITCONF80percent4STACKBAR150bar03mms518g.txt\", #13\n",
    "#         \"force_start\"   : \"31.07.2025 15:16:03.864139\",\n",
    "#         \"force_end\"     : \"31.07.2025 15:16:18.464139\",\n",
    "#         \"pos_start\"     : \"31.07.2025 15:16:18.464139\",\n",
    "#         \"pos_end\"       : \"31.07.2025 15:20:00.584139\"  \n",
    "#     }\n",
    "\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the CSV data from the first file_info\n",
    "# index_master = 10  # or whichever index you want\n",
    "# master_info = file_info[index_master]\n",
    "\n",
    "# df_master = pd.read_csv(\n",
    "#     master_info[\"path\"],\n",
    "#     encoding='utf-16-le',\n",
    "#     sep=';',\n",
    "#     skiprows=1,\n",
    "#     quotechar='\"'\n",
    "# )\n",
    "\n",
    "# # Clean and preprocess\n",
    "# df_master = df_master.rename(columns={\n",
    "#     'time': 'Time',\n",
    "#     'dbPr\\\\diIstKraftGes': 'Force'\n",
    "# })\n",
    "# df_master = df_master[['Time', 'Force']]\n",
    "# df_master['Force'] = df_master['Force'].astype(str).str.replace(',', '.', regex=False)\n",
    "# df_master['Force'] = pd.to_numeric(df_master['Force'], errors='coerce')\n",
    "# df_master = df_master[df_master['Time'] != 'sec']\n",
    "# df_master['Time'] = pd.to_datetime(df_master['Time'], format='%d.%m.%Y %H:%M:%S.%f')\n",
    "\n",
    "# # Time filter and alignment\n",
    "# force_start = pd.to_datetime(master_info[\"force_start\"], format='%d.%m.%Y %H:%M:%S.%f')\n",
    "# force_end = pd.to_datetime(master_info[\"force_end\"], format='%d.%m.%Y %H:%M:%S.%f')\n",
    "# master_df = df_master[(df_master['Time'] >= force_start) & (df_master['Time'] <= force_end)].copy()\n",
    "# master_df['Time_seconds'] = (master_df['Time'] - master_df['Time'].iloc[0]).dt.total_seconds()\n",
    "\n",
    "# # Extract time and force as NumPy arrays\n",
    "# real_time = master_df['Time_seconds'].to_numpy()\n",
    "# real_force = master_df['Force'].to_numpy() /  9.80665\n",
    "\n",
    "# # Optional: resample master curve on a common time grid\n",
    "# common_time = np.linspace(0.0, real_time.max(), num=200)\n",
    "# real_force_resampled = np.interp(common_time, real_time, real_force)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_LHS_parameters.csv')\n",
    "\n",
    "n_values = df['n'].tolist()\n",
    "tau_star_values = df['tau_star'].tolist()\n",
    "# B_values = df['B'].tolist()\n",
    "tau_w_values = df['tau_w'].tolist()\n",
    "m_values = df['m'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moldflow Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 1 with \n",
      "n : 0.9416036385905784\n",
      "tau_star : 153612.03670543525\n",
      "tau_w : 0.2548863537027709\n",
      "m : 0.6004306096626426\n",
      "Simulation 2 with \n",
      "n : 0.8038895180823131\n",
      "tau_star : 195649.4594493557\n",
      "tau_w : 0.736742292379642\n",
      "m : 1.6593989032112682\n",
      "Simulation 3 with \n",
      "n : 0.0917068964595216\n",
      "tau_star : 323623.8235745369\n",
      "tau_w : 0.048330410534807\n",
      "m : 0.4025302969253785\n",
      "Simulation 4 with \n",
      "n : 0.5411172089386926\n",
      "tau_star : 47553.990305868734\n",
      "tau_w : 0.3511112110673176\n",
      "m : 0.7006687681587517\n",
      "Simulation 5 with \n",
      "n : 0.2242629623983043\n",
      "tau_star : 265011.59908144845\n",
      "tau_w : 0.186910371693733\n",
      "m : 1.1394463553283594\n",
      "Simulation 6 with \n",
      "n : 0.4840719321588449\n",
      "tau_star : 20105.43935102504\n",
      "tau_w : 0.6775681420688854\n",
      "m : 1.861729504942771\n",
      "Simulation 7 with \n",
      "n : 0.6232496450207361\n",
      "tau_star : 295185.9591318524\n",
      "tau_w : 0.5899878389168749\n",
      "m : 1.5202707300506155\n",
      "Simulation 8 with \n",
      "n : 0.333950301072446\n",
      "tau_star : 113977.2162116709\n",
      "tau_w : 0.4107290512975221\n",
      "m : 0.9959870196379448\n",
      "Simulation 9 with \n",
      "n : 0.7713867759919342\n",
      "tau_star : 228595.58971956215\n",
      "tau_w : 0.9044605798015204\n",
      "m : 1.3567028282203455\n",
      "Simulation 10 with \n",
      "n : 0.1761663019481406\n",
      "tau_star : 365224.01522557327\n",
      "tau_w : 0.8143564680805521\n",
      "m : 0.2272791195887101\n"
     ]
    }
   ],
   "source": [
    "Synergy = win32com.client.Dispatch(\"synergy.Synergy\")\n",
    "Synergy.SetUnits(\"Metric\")\n",
    "moldflow = \"C:\\\\Program Files\\\\Autodesk\\\\Moldflow Insight 2026\\\\bin\"                        #Home D:\\\\Moldflow Insight 2023\\\\bin       #WS \"C:\\\\Program Files\\\\Autodesk\\\\Moldflow Insight 2023\\\\bin\"  #\"G:\\\\Oskay Sözen\\\\wall_slip\\\\wall slip.mpi\"\n",
    "\n",
    "\n",
    "Synergy.OpenProject(\"G:\\\\Oskay Sözen\\\\viscosity\\\\viscosity.mpi\")\n",
    "Project = Synergy.Project\n",
    "Project.OpenItemByName(\"80CENTER_study\", \"Study\")\n",
    "\n",
    "\n",
    "\n",
    "#Simulation loop for wall slip parameters\n",
    "for i in range(10):\n",
    "\n",
    "    n = n_values[i]\n",
    "    tau_star = tau_star_values[i]\n",
    "    # B = B_values[i]\n",
    "    tau_w = tau_w_values[i]\n",
    "    m = m_values[i]\n",
    "\n",
    "\n",
    "    print(f\"Simulation {i+1} with \\nn : {n}\\ntau_star : {tau_star}\\ntau_w : {tau_w}\\nm : {m}\")\n",
    "\n",
    "    study_name = f\"study_{i+1}\"\n",
    "    Project = Synergy.Project\n",
    "\n",
    "    # Viscosity Parameters\n",
    "\n",
    "    PropEd = Synergy.PropertyEditor\n",
    "    Prop = PropEd.FindProperty(10090,1)\n",
    "    Prop.FieldDescription(53030, f\"{n}, {tau_star}, 1.916e+19, 0.004, 0, 0, 0.305\")\n",
    "    PropEd.CommitChanges(\"Process Conditions\")\n",
    "\n",
    "    # Wall Slip Parameters\n",
    "\n",
    "    PropEd = Synergy.PropertyEditor\n",
    "    Prop = PropEd.FindProperty(10090, 1)\n",
    "    DVec = Synergy.CreateDoubleArray\n",
    "    \n",
    "    DVec.AddDouble(tau_w)\n",
    "    DVec.AddDouble(m)\n",
    "    DVec.AddDouble(1e-08)\n",
    "    DVec.AddDouble(0)\n",
    "    DVec.AddDouble(0)\n",
    "    \n",
    "    Prop.FieldValues(51182, DVec)\n",
    "        \n",
    "    PropEd.CommitChanges(\"Process Conditions\")\n",
    "\n",
    "    StudyDoc = Synergy.StudyDoc\n",
    "    StudyDoc.SaveAs(study_name)\n",
    "\n",
    "    p = subprocess.Popen(\n",
    "    [os.path.join(moldflow, \"runstudy.exe\"), f\"G:\\\\Oskay Sözen\\\\viscosity\\\\study_{i+1}.sdy\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    )\n",
    "    (output, err) = p.communicate()\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Restart of the Synergy to prevent XML saving crash\n",
    "    \n",
    "    subprocess.run([\"taskkill\", \"/f\", \"/im\", \"airsyn_synergy.exe\"]) \n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    Synergy.OpenProject(\"G:\\\\Oskay Sözen\\\\viscosity\\\\viscosity.mpi\")         # PROJECT NAME!!!!!!!!!!!!!!!!\n",
    "    Project = Synergy.Project\n",
    "    Project.OpenItemByName(f\"study_{i+1}\", \"Study\")\n",
    "\n",
    "    # Plot Export\n",
    "\n",
    "    PlotMgr = Synergy.PlotManager\n",
    "    time.sleep(3)\n",
    "    Plot = PlotMgr.FindPlotByName2(\"Press force:XY Plot\", \"Press force\")\n",
    "    Pid = Plot.GetDataID\n",
    "    PlotMgr = None\n",
    "    PlotMgr = Synergy.PlotManager\n",
    "    time.sleep(3)\n",
    "    PlotMgr.SaveResultDataInXML2( Pid, f\"H:\\\\XMLFiles\\\\study_{i + 1}_force.xml\", \"Metric\")\n",
    "\n",
    "    PlotMgr = Synergy.PlotManager\n",
    "    time.sleep(3)\n",
    "    Plot = PlotMgr.FindPlotByName2(\"Press displacement:XY Plot\", \"Press displacement\")\n",
    "    Pid = Plot.GetDataID\n",
    "    PlotMgr = None\n",
    "    PlotMgr = Synergy.PlotManager\n",
    "    time.sleep(3)\n",
    "    PlotMgr.SaveResultDataInXML2( Pid, f\"H:\\\\XMLFiles\\\\study_{i + 1}_disp.xml\", \"Metric\")\n",
    "\n",
    "\n",
    "# Write the output to a log file\n",
    "    with open(f\"H:\\\\Log_Files\\\\study_{i+1}.log\", \"w\") as file:\n",
    "        file.write(output.decode(\"windows-1252\").strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML Parsing - Guess Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_disp_data_all = {}\n",
    "guess_force_data_all = {}\n",
    "area_data = []\n",
    "guess_data_all = {}\n",
    "\n",
    "valid_xml = []\n",
    "for i in range(10):\n",
    "        guess_tree = ET.parse(f\"H:\\\\XMLFiles\\\\study_{i + 1}_force.xml\")\n",
    "        guess_root = guess_tree.getroot()\n",
    "        guess_data = []\n",
    "\n",
    "        count = 0\n",
    "                \n",
    "        for time_block, dept_block in zip(guess_root.findall('.//Block//IndpVar'), guess_root.findall('.//Block')):\n",
    "                if count >= 35:\n",
    "                        break\n",
    "\n",
    "\n",
    "                time_value = time_block.attrib.get('Value')\n",
    "                dept_value = dept_block.find('DeptValues').text.strip()\n",
    "                \n",
    "                guess_data.append((time_value, dept_value))\n",
    "\n",
    "                count += 1\n",
    "        if len(guess_data) < 27:\n",
    "                print(f\"Warning: File {i+1} has incomplete or corrupted data (only {len(guess_data)} entries). Skipping.\")\n",
    "                continue\n",
    "\n",
    "        guess_data_all[f\"guess_data_{i+1}\"] = guess_data\n",
    "\n",
    "        guess_data_array = np.array([(float(x), float(y)) for x, y in guess_data])\n",
    "        guess_time = guess_data_array[:, 0]  \n",
    "        guess_disp = guess_data_array[:, 1] * 9.80665\n",
    "\n",
    "        globals()[f\"guess_time_{i+1}\"] = guess_time\n",
    "        globals()[f\"guess_disp_{i+1}\"] = guess_disp \n",
    "\n",
    "\n",
    "        mean_s_error = calculate_area_between_curves(real_time, real_disp, guess_time, guess_disp)\n",
    "        area_data.append(mean_s_error)\n",
    "        valid_xml.append(len(area_data) - 1)\n",
    "\n",
    "        \n",
    "print(guess_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(area_data)\n",
    "print(list(guess_data_all.keys()))\n",
    "for name, lst in guess_data_all.items():\n",
    "    array = np.array(lst)\n",
    "    print(f\"{name}: Shape = {array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_time = np.linspace(0.0, max(real_time.max(), guess_time.max()), num=200)\n",
    "real_force_resampled = np.interp(common_time, real_time, real_disp)\n",
    "\n",
    "num_curves = len(guess_data_all)\n",
    "colormap = plt.get_cmap('viridis')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, (key, guess_data) in enumerate(guess_data_all.items(), start=1):\n",
    "    if isinstance(guess_data[0], (list, tuple)) and len(guess_data[0]) == 2:\n",
    "        guess_data_array = np.array([(float(x), float(y)) for x, y in guess_data])\n",
    "        guess_time = guess_data_array[:, 0]\n",
    "        guess_force = guess_data_array[:, 1] * 9.80665\n",
    "\n",
    "    guess_force_resampled = np.interp(common_time, guess_time, guess_force)\n",
    "    color = colormap((i - 1) / max(num_curves - 1, 1))\n",
    "    plt.plot(common_time, guess_force_resampled, color=color, label=f'Guess_{i}')\n",
    "\n",
    "plt.plot(common_time, real_force_resampled, 'b-', label='Real Curve', linewidth=2)\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Force (kN)')\n",
    "plt.title('Force vs Time (Guess vs Real)')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'H:\\\\moldflow\\\\moldflow_automation\\\\combined_LHS_parameters.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "n_values = data['n'].values\n",
    "tau_star_values = data['tau_star'].values\n",
    "# B_values = data['B'].values\n",
    "tau_w_values = data['tau_w'].values\n",
    "m_values = data['m'].values\n",
    "\n",
    "train_x = torch.tensor([[n_values[i], tau_star_values[i], tau_w_values[i], m_values[i]] for i in valid_xml ], dtype=torch.float64)\n",
    "train_y = - torch.tensor([[area_data[i]] for i in valid_xml], dtype=torch.float64)\n",
    "train_yvar = torch.full_like(train_y, 1e-6)\n",
    "\n",
    "\n",
    "\n",
    "bounds = torch.tensor([\n",
    "    [0.1, 500.0, 0.001, 0.1],\n",
    "    [1.0, 8000.0, 1.0, 1.9]\n",
    "], dtype= torch.float64\n",
    ")\n",
    "\n",
    "outcome_transform = Standardize(m=1)\n",
    "input_transform = Normalize(d=4)\n",
    "\n",
    "# GP Model \n",
    "model = SingleTaskGP(train_x, train_y,train_Yvar=train_yvar, outcome_transform=outcome_transform, input_transform=input_transform)\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "model.eval()  \n",
    "\n",
    "\n",
    "acq_func =  LogExpectedImprovement(model, best_f=train_y.max().item())\n",
    "\n",
    "candidate, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=1000, #Helps to ensure that we find the global optimum instead of finding the local optimum\n",
    "        raw_samples=5000,  #More samples increases likelihood of finding good starting point.\n",
    ")\n",
    "\n",
    "cand = model(input_transform(candidate))\n",
    "cand_var = torch.diagonal(cand.covariance_matrix, 0)\n",
    "cand_mean, cand_std = outcome_transform.untransform(cand.mean, cand_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(candidate)\n",
    "print(train_y)\n",
    "print(train_x)\n",
    "bounds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization CHECK CANDIDATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_data_all_optim = {}\n",
    "num_iteration = 5\n",
    "iterations=[]\n",
    "\n",
    "for i in range(num_iteration):\n",
    "    outcome_transform = Standardize(m=1)\n",
    "    input_transform = Normalize(d=5)\n",
    "\n",
    "    model = SingleTaskGP(train_x, train_y,train_Yvar=train_yvar, outcome_transform=outcome_transform, input_transform=input_transform)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    model.eval()  \n",
    "\n",
    "    acq_func =  LogExpectedImprovement(model, best_f=train_y.max())\n",
    "\n",
    "\n",
    "    candidate_optim, _ = optimize_acqf(\n",
    "            acq_function=acq_func,\n",
    "            bounds=bounds,\n",
    "            q=1,\n",
    "            num_restarts=1000, #Helps to ensure that we find the global optimum instead of finding the local optimum\n",
    "            raw_samples=5000,  #More samples increases likelihood of finding good starting point.\n",
    "    )\n",
    "\n",
    "    print(f\"Iteration {i+1}: Suggested new parameters (n, tau_star, B, tau_w, m)\", candidate_optim)\n",
    "    iterations.append(candidate_optim)\n",
    "\n",
    "    study_name = f\"optimization_{i+1}\"\n",
    "    Project = Synergy.Project\n",
    "\n",
    "    # Viscosity Parameters\n",
    "\n",
    "    PropEd = Synergy.PropertyEditor\n",
    "    Prop = PropEd.FindProperty(10090,1)\n",
    "    Prop.FieldDescription(53030, f\"{candidate_optim[0,0].item()}, {candidate_optim[0,1].item()}, 1e+08, 0.004, 0, 0, 0.305\")\n",
    "    PropEd.CommitChanges(\"Process Conditions\")\n",
    "\n",
    "    # Wall Slip Parameters\n",
    "\n",
    "    PropEd = Synergy.PropertyEditor\n",
    "    Prop = PropEd.FindProperty(10090, 1)\n",
    "    DVec = Synergy.CreateDoubleArray\n",
    "    \n",
    "    DVec.AddDouble(candidate_optim[0,2].item())\n",
    "    DVec.AddDouble(candidate_optim[0,3].item())\n",
    "    DVec.AddDouble(1e-08)\n",
    "    DVec.AddDouble(0)\n",
    "    DVec.AddDouble(0)\n",
    "    \n",
    "    Prop.FieldValues(51182, DVec)\n",
    "        \n",
    "    PropEd.CommitChanges(\"Process Conditions\")\n",
    "\n",
    "    StudyDoc = Synergy.StudyDoc\n",
    "    StudyDoc.SaveAs(study_name)\n",
    "\n",
    "    p = subprocess.Popen(\n",
    "    [os.path.join(moldflow, \"runstudy.exe\"), f\"G:\\\\Oskay Sözen\\\\viscosity\\\\optimization_{i+1}.sdy\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    )\n",
    "    (output, err) = p.communicate()\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    Synergy.OpenProject(\"G:\\\\Oskay Sözen\\\\viscosity\\\\viscosity.mpi\")         # PROJECT NAME!!!!!!!!!!!!!!!!\n",
    "    Project = Synergy.Project\n",
    "    Project.OpenItemByName(f\"optimization_{i+1}\", \"Study\")\n",
    "\n",
    "    # Plot Export\n",
    "\n",
    "    PlotMgr = Synergy.PlotManager\n",
    "    time.sleep(3)\n",
    "    Plot = PlotMgr.FindPlotByName2(\"Press force:XY Plot\", \"Press force\")\n",
    "    Pid = Plot.GetDataID\n",
    "    PlotMgr = None\n",
    "    PlotMgr = Synergy.PlotManager\n",
    "    time.sleep(3)\n",
    "    PlotMgr.SaveResultDataInXML2( Pid, f\"H:\\\\XMLFiles\\\\optimization_{i + 1}.xml\", \"Metric\")\n",
    "\n",
    "\n",
    "\n",
    "# Write the output to a log file\n",
    "    with open(f\"H:\\\\Log_Files\\\\optimization_{i+1}.log\", \"w\") as file:\n",
    "        file.write(output.decode(\"windows-1252\").strip())\n",
    "\n",
    "    guess_tree = ET.parse(f\"H:\\\\XMLFiles\\\\optimization_{i+1}.xml\")\n",
    "    guess_root = guess_tree.getroot()\n",
    "    guess_data = []\n",
    "    time.sleep(1) \n",
    "    count = 0   \n",
    "    for time_block, dept_block in zip(guess_root.findall('.//Block//IndpVar'), guess_root.findall('.//Block')):\n",
    "        if count >= 30:\n",
    "            break\n",
    "        \n",
    "        time_value = time_block.attrib.get('Value')\n",
    "        dept_value = dept_block.find('DeptValues').text.strip()\n",
    "        guess_data.append((time_value, dept_value))\n",
    "\n",
    "        count += 1\n",
    "    if len(guess_data) < 30:\n",
    "        print(f\"Warning: File {i+1} has incomplete or corrupted data (only {len(guess_data)} entries). Skipping.\")\n",
    "        continue\n",
    "    guess_data_all_optim[f\"guess_data_{i+1}\"] = guess_data\n",
    "\n",
    "    guess_data_array = np.array([(float(x), float(y)) for x, y in guess_data])\n",
    "    guess_time = guess_data_array[:, 0]  \n",
    "    guess_disp = guess_data_array[:, 1]  \n",
    "        \n",
    "    globals()[f\"guess_time_{5 + num_iteration}\"] = guess_time\n",
    "    globals()[f\"guess_disp_{5 + num_iteration}\"] = guess_disp\n",
    "    \n",
    "    mean_s_error = calculate_area_between_curves(real_time, real_disp, guess_time, guess_disp)\n",
    "    area_data.append(mean_s_error)\n",
    "    valid_xml.append(len(area_data) - 1)\n",
    "\n",
    "    # New Values\n",
    "\n",
    "    train_x = torch.cat([train_x, candidate_optim], dim=0)\n",
    "    train_y = torch.cat([train_y, -torch.tensor([[area_data[-1]]])], dim=0)\n",
    "    train_yvar = torch.full_like(train_y, 1e-6)\n",
    "\n",
    "    current_best_area = train_y.max().item()\n",
    "\n",
    "    if abs(current_best_area) < 1e-2:\n",
    "        print(f\"Converged after {i+1} iteration\")\n",
    "        break\n",
    "    \n",
    "best_params = train_x[train_y.argmax()]\n",
    "best_area = train_y.max().item()\n",
    "print(f\"Best parameters (n, tau_star, B, tau_w, m): {best_params}, with MSE : {best_area}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_curves = len(guess_data_all)\n",
    "colormap = plt.get_cmap('viridis')\n",
    "for i, (key, guess_data) in enumerate(guess_data_all.items(), start=1):\n",
    "    if isinstance(guess_data[0], (list, tuple)) and len(guess_data[0]) == 2:\n",
    "        guess_data_array = np.array([(float(x), float(y)) for x, y in guess_data])\n",
    "        guess_time = guess_data_array[:, 0]\n",
    "        guess_disp = guess_data_array[:, 1]\n",
    "\n",
    "    guess_disp_resampled = np.interp(common_time, guess_time, guess_disp)\n",
    "\n",
    "    \n",
    "    color = colormap((i - 1) / max(num_curves - 1, 1))\n",
    "    plt.plot(common_time, guess_disp_resampled, color=color, label=f'Guess_{i}')\n",
    "\n",
    "\n",
    "real_disp_resampled = np.interp(common_time, real_time, real_disp)\n",
    "plt.plot(common_time, real_disp_resampled, 'b-', label='Real Curve', linewidth=2)\n",
    "\n",
    "# Finalize plot\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Force')\n",
    "plt.title('Force vs Time (5 Random Guess Curves)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_curves = len(guess_data_all_optim)\n",
    "colormap = plt.get_cmap('viridis', num_curves)  \n",
    "plt.plot(common_time, real_disp_resampled, 'b-', label='Real Curve')\n",
    "for i, (key, guess_data) in enumerate(guess_data_all_optim.items()):\n",
    "    if isinstance(guess_data[0], (list, tuple)) and len(guess_data[0]) == 2:\n",
    "        guess_data_array = np.array([(float(x), float(y)) for x, y in guess_data])\n",
    "        guess_time = guess_data_array[:, 0]\n",
    "        guess_disp = guess_data_array[:, 1]\n",
    "\n",
    "        guess_disp_resampled = np.interp(common_time, guess_time, guess_disp)\n",
    "\n",
    "        color = colormap(i) \n",
    "        plt.plot(common_time, guess_disp_resampled, color=color, label=f'Guess_{i+1}')\n",
    "\n",
    "# Finalize plot\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Force')\n",
    "plt.title('Force vs Time (Optimized Curves)')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
